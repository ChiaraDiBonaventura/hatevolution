{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXgorNjr4JSOD+49kH274q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KXGH26PMms5U"},"outputs":[],"source":["import pandas as pd\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","path = # your path here"]},{"cell_type":"code","source":["def get_f1(f1_type, year=None):\n","  \"\"\"\n","  it returns the eval metrics by the year specified. If no year is passed, eval metrics are computed on the overall dataset.\n","  @params:\n","  f1_type = 'macro avg', '1' if hateful label, '0' if non-hateful label\n","  \"\"\"\n","\n","  if year!=None:\n","    sub_df = df[df['year']==year]\n","  else:\n","    sub_df = df\n","\n","  true_labels = sub_df['label'].to_list()\n","  predictions = sub_df['results'].replace({'toxic':1, 'respectful':0})\n","  report = classification_report(true_labels, predictions, zero_division=False, digits=4, output_dict=True)\n","\n","  print(classification_report(true_labels, predictions, zero_division=False, digits=4))\n","\n","  return report[f1_type]['f1-score']"],"metadata":{"id":"0ilKHIhjm1SA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_support_size(f1_type, year=None):\n","  \"\"\"\n","  it returns the support size for each year. If no year is passed, eval metrics are computed on the overall dataset.\n","  \"\"\"\n","\n","  if year!=None:\n","    sub_df = df[df['year']==year]\n","  else:\n","    sub_df = df\n","\n","  true_labels = sub_df['label'].to_list()\n","  predictions = sub_df['results'].replace({'toxic':1, 'respectful':0})\n","  report = classification_report(true_labels, predictions, zero_division=False, digits=4, output_dict=True)\n","\n","  return report[f1_type]['support']"],"metadata":{"id":"MmEm2wSYm1PO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["expected_answers = ['respectful', 'toxic']\n","def get_misbehavior_rate(model_answer):\n","    if model_answer in expected_answers:\n","        return \"Expected\"\n","    else:\n","        return \"Unexpected\""],"metadata":{"id":"p60PhnNom1JS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f1_type = input(\"Do you want 'macro avg', '1' or '0' F1 score? \")"],"metadata":{"id":"S_Bma25Wm7_m"},"execution_count":null,"outputs":[]}]}